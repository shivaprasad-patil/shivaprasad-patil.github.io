---
title: "Reproducing GPT-2"
collection: projects

date: 2025-06-29
github: "https://github.com/shivaprasad-patil/nano_GPT-2"
---

ğŸ§ ğŸ’¬ ChatGPT has become an integral part of my daily life. I became increasingly intrigued to understand what was going on *under the hood* of the GPT model and spent my weekends ğŸ› ï¸ building a GPT model â€” aiming to replicate OpenAIâ€™s GPT-2 (124M) model.

ğŸ“ğŸ“š **Andrej Karpathyâ€™s** lecture series is hands-down the best resource to learn about **Deep Learning** and **LLMs**.

ğŸš€ After a lot of tinkering, I finally completed building my GPT model and began training it on a piece of internet data. This whole journey made me appreciate even more the **incredible ingenuity** and **exceptional engineering** that goes into OpenAIâ€™s models. ğŸ™Œ

ğŸ¤– I'm eagerly awaiting the launch of OpenAIâ€™s **open-source reasoning model**, and now that Iâ€™ve got a better grasp of how LLMs work, Iâ€™m *super excited* to start applying them in my projects! ğŸ”âš™ï¸

---

**ğŸ“‚ GitHub Repository:** [nano GPT-2](https://github.com/shivaprasad-patil/nano_GPT-2)

**ğŸ¥ Neural Networks: Zero to Hero by Andrej Karpathy:** [Lecture Series](https://www.youtube.com/playlist?list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ)

ğŸ§ª **Finally training my model:**
    ![Project Image](/files/gpt_2 Medium.jpeg)
